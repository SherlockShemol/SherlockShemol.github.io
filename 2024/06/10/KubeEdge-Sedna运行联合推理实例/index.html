<!DOCTYPE html><html lang="zh-CN"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><meta name="author"><title>KubeEdge-Sedna运行联合推理实例 · Shemol's Blog</title><meta name="description" content="按照上篇文章已经部署好了KubeEdge、EdgeMesh和Sedna，接下来按照官方文档运行联合推理实例。官方文档：https://sedna.readthedocs.io/en/latest/examples/joint_inference/helmet_detection_inference/"><meta name="og:description" content="按照上篇文章已经部署好了KubeEdge、EdgeMesh和Sedna，接下来按照官方文档运行联合推理实例。官方文档：https://sedna.readthedocs.io/en/latest/examples/joint_inference/helmet_detection_inference/"><meta name="twitter:site" content="Shemol's Blog"><meta name="twitter:title" content="KubeEdge-Sedna运行联合推理实例"><meta name="twitter:card" content="summary"><meta name="keywords" content=""><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="renderer" content="webkit"><link rel="short icon" href="images/favicon.png" type="image/x-icon"><link rel="stylesheet" href="/css/bootstrap.min.css"><link rel="stylesheet" href="/css/font-awesome.min.css"><link rel="stylesheet" href="/css/style.css"><link rel="alternate" type="application/atom+xml" title="ATOM 1.0" href="/atom.xml"><meta name="generator" content="Hexo 7.3.0"><link rel="stylesheet" href="/css/prism.css" type="text/css">
<link rel="stylesheet" href="/css/prism-line-numbers.css" type="text/css"></head><body><div class="container" id="stage"><div class="row"><div class="col-sm-3 col-xs-12 side-container invisible" id="side-bar"><div class="vertical-text site-title"><h3 class="site-title-small" tabindex="-1"><a class="a-title" href="/">Shemol's Blog</a></h3><h1 class="site-title-large" tabindex="-1"><a class="a-title" href="/"></a></h1><!--h6(onclick="triggerSiteNav()") Trigger--></div><br class="visible-lg visible-md visible-sm"><div class="site-title-links" id="site-nav"><ul><li><a href="/">Home</a></li><li><a href="/archives">Archive</a></li><li><a href="/tags">Tags</a></li><li><a href="/about/index.html">about</a></li><li><a href="/friends/index.html">friends</a></li><li class="soc"></li></ul><div class="visible-lg visible-md visible-sm site-nav-footer"><br class="site-nav-footer-br"><footer><p>&copy;&nbsp;2024&nbsp;<a target="_blank" href="https://shemol.tech" rel="noopener noreferrer">Shemol</a></p><p>Theme&nbsp;<a target="_blank" href="https://github.com/SumiMakito/hexo-theme-typography" rel="noopener noreferrer">Typography</a>&nbsp;by&nbsp;<a target="_blank" href="https://www.keep.moe" rel="noopener noreferrer">Makito</a></p><p>Proudly published with&nbsp;<a target="_blank" href="https://hexo.io" rel="noopener noreferrer">Hexo</a></p></footer></div></div></div><div class="col-sm-9 col-xs-12 main-container invisible" id="main-container"><div class="autopagerize_page_element"><div class="content"><div class="post-page"><div class="post-container"><p class="post-title"><a>KubeEdge-Sedna运行联合推理实例</a></p><p class="post-meta"><span class="date meta-item">Posted at&nbsp;2024-06-10</span><span class="meta-item"><i class="fa fa-tag"></i><span>&nbsp;</span><a class="a-tag" href="/tags/KubeEdge/" title="KubeEdge">KubeEdge</a><span>&nbsp;</span><a class="a-tag" href="/tags/流程记录/" title="流程记录">流程记录</a><span>&nbsp;</span></span></p><p class="post-abstract"><span id="more"></span>
<p>按照上篇文章已经部署好了KubeEdge、EdgeMesh和Sedna，接下来按照官方文档运行联合推理实例。<br>官方文档：<a target="_blank" rel="noopener" href="https://sedna.readthedocs.io/en/latest/examples/joint_inference/helmet_detection_inference/README.html#">https://sedna.readthedocs.io/en/latest/examples/joint_inference/helmet_detection_inference/README.html#</a><br>其实只要之前的EdgeMesh正确部署，这个实例只要按照文档不会出问题。</p>
<h1 id="准备数据和模型"><a href="#准备数据和模型" class="headerlink" title="准备数据和模型"></a>准备数据和模型</h1><ul>
<li><p>下载小模型到边端</p>
<figure class="highlight bash"><table><tr><td class="code"><pre class="line-numbers language-hljs bash"><span class="hljs-built_in">mkdir</span> -p /data/little-model<br><span class="hljs-built_in"><code class="language-hljs bash"><span class="hljs-built_in">mkdir</span> -p /data/little-model<br><span class="hljs-built_in">cd</span> /data/little-model<br>wget https://kubeedge.obs.cn-north-1.myhuaweicloud.com/examples/helmet-detection-inference/little-model.tar.gz<br>tar -zxvf little-model.tar.gz<br><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></td></tr></table></figure>
</li>
<li><p>下载大模型到云端</p>
<figure class="highlight bash"><table><tr><td class="code"><pre class="line-numbers language-hljs bash"><span class="hljs-built_in">mkdir</span> -p /data/big-model<br><span class="hljs-built_in"><code class="language-hljs bash"><span class="hljs-built_in">mkdir</span> -p /data/big-model<br><span class="hljs-built_in">cd</span> /data/big-model<br>wget https://kubeedge.obs.cn-north-1.myhuaweicloud.com/examples/helmet-detection-inference/big-model.tar.gz<br>tar -zxvf big-model.tar.gz<br><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></td></tr></table></figure></li>
<li><p>准备镜像<br>小模型推理worker：<code>kubeedge/sedna-example-joint-inference-helmet-detection-little:v0.3.0</code><br>大模型推理worker：<code>kubeedge/sedna-example-joint-inference-helmet-detection-big:v0.3.0</code></p>
</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre class="line-numbers language-hljs bash">git <span class="hljs-built_in">clone</span> https://github.com/kubeedge/sedna.git<br>./examples/build_image.sh joint_inference <span class="hljs-comment"><code class="language-hljs bash">git <span class="hljs-built_in">clone</span> https://github.com/kubeedge/sedna.git<br>./examples/build_image.sh joint_inference <span class="hljs-comment"># 后面加joint_inference就只生成联合推理的镜像，不加的话就把包括联邦学习那些都生成了</span><br><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></td></tr></table></figure>
<p>如果很慢的话，我的做法是在构建镜像的文件中（<code>joint-inference-helmet-detection-big.Dockerfile</code>和<code>joint-inference-helmet-detection-little.Dockerfile</code>）加入</p>
<figure class="highlight dockerfile"><table><tr><td class="code"><pre class="line-numbers language-hljs dockerfile"><span class="hljs-keyword">RUN</span><span class="language-bash"> sed -i s@/archive.ubuntu.com/@/mirrors.aliyun.com/@g /etc/apt/sources.list</span><br><span class="hljs-keyword">RUN</span><span class="language-bash"> apt-get clean </span><br><span class="hljs-keyword">RUN</span><span class="language-bash"> pip config <span class="hljs-built_in">set</span> global.index-url http://mirrors.aliyun.com/pypi/simple</span><br><span class="hljs-keyword">RUN</span><span class="language-bash"> pip config <span class="hljs-built_in">set</span> install.trusted-host mirrors.aliyun.com</span><br><span class="hljs-keyword">RUN</span><span class="language-bash"><code class="language-hljs dockerfile"><span class="hljs-keyword">RUN</span><span class="language-bash"> sed -i s@/archive.ubuntu.com/@/mirrors.aliyun.com/@g /etc/apt/sources.list</span><br><span class="hljs-keyword">RUN</span><span class="language-bash"> apt-get clean </span><br><span class="hljs-keyword">RUN</span><span class="language-bash"> pip config <span class="hljs-built_in">set</span> global.index-url http://mirrors.aliyun.com/pypi/simple</span><br><span class="hljs-keyword">RUN</span><span class="language-bash"> pip config <span class="hljs-built_in">set</span> install.trusted-host mirrors.aliyun.com</span><br><span class="hljs-keyword">RUN</span><span class="language-bash"> pip install --upgrade pip</span><br><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></td></tr></table></figure>
<p>添加apt和pip镜像源。</p>
<h1 id="创建联合推理服务"><a href="#创建联合推理服务" class="headerlink" title="创建联合推理服务"></a>创建联合推理服务</h1><p>（kubectl的操作全是在云端进行）</p>
<ul>
<li>为云端创建大模型资源对象<figure class="highlight bash"><table><tr><td class="code"><pre class="line-numbers language-hljs bash">kubectl create -f - &lt;&lt;<span class="hljs-string">EOF</span><br><span class="hljs-string">apiVersion: sedna.io/v1alpha1</span><br><span class="hljs-string">kind:  Model</span><br><span class="hljs-string">metadata:</span><br><span class="hljs-string">  name: helmet-detection-inference-big-model</span><br><span class="hljs-string">  namespace: default</span><br><span class="hljs-string">spec:</span><br><span class="hljs-string">  url: &quot;/data/big-model/yolov3_darknet.pb&quot;</span><br><span class="hljs-string">  format: &quot;pb&quot;</span><br><span class="hljs-string"><code class="language-hljs bash">kubectl create -f - &lt;&lt;<span class="hljs-string">EOF</span><br><span class="hljs-string">apiVersion: sedna.io/v1alpha1</span><br><span class="hljs-string">kind:  Model</span><br><span class="hljs-string">metadata:</span><br><span class="hljs-string">  name: helmet-detection-inference-big-model</span><br><span class="hljs-string">  namespace: default</span><br><span class="hljs-string">spec:</span><br><span class="hljs-string">  url: &quot;/data/big-model/yolov3_darknet.pb&quot;</span><br><span class="hljs-string">  format: &quot;pb&quot;</span><br><span class="hljs-string">EOF</span><br><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></td></tr></table></figure></li>
<li>为边缘端创建小模型资源对象<figure class="highlight bash"><table><tr><td class="code"><pre class="line-numbers language-hljs bash">kubectl create -f - &lt;&lt;<span class="hljs-string">EOF</span><br><span class="hljs-string">apiVersion: sedna.io/v1alpha1</span><br><span class="hljs-string">kind: Model</span><br><span class="hljs-string">metadata:</span><br><span class="hljs-string">  name: helmet-detection-inference-little-model</span><br><span class="hljs-string">  namespace: default</span><br><span class="hljs-string">spec:</span><br><span class="hljs-string">  url: &quot;/data/little-model/yolov3_resnet18.pb&quot;</span><br><span class="hljs-string">  format: &quot;pb&quot;</span><br><span class="hljs-string"><code class="language-hljs bash">kubectl create -f - &lt;&lt;<span class="hljs-string">EOF</span><br><span class="hljs-string">apiVersion: sedna.io/v1alpha1</span><br><span class="hljs-string">kind: Model</span><br><span class="hljs-string">metadata:</span><br><span class="hljs-string">  name: helmet-detection-inference-little-model</span><br><span class="hljs-string">  namespace: default</span><br><span class="hljs-string">spec:</span><br><span class="hljs-string">  url: &quot;/data/little-model/yolov3_resnet18.pb&quot;</span><br><span class="hljs-string">  format: &quot;pb&quot;</span><br><span class="hljs-string">EOF</span><br><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></td></tr></table></figure>
在边端创建文件夹，生成的推理图片结果都生成在文件夹中：<figure class="highlight bash"><table><tr><td class="code"><pre class="line-numbers language-hljs bash"><span class="hljs-built_in"><code class="language-hljs bash"><span class="hljs-built_in">mkdir</span> -p /joint_inference/output<br><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></td></tr></table></figure>
在云端定义环境变量CLOUD_NODE和EDGE_NODE<figure class="highlight bash"><table><tr><td class="code"><pre class="line-numbers language-hljs bash">CLOUD_NODE=<span class="hljs-string">&quot;cloud-node-name&quot;</span><br>EDGE_NODE=<span class="hljs-string"><code class="language-hljs bash">CLOUD_NODE=<span class="hljs-string">&quot;cloud-node-name&quot;</span><br>EDGE_NODE=<span class="hljs-string">"edge-node-name"</span><br><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></td></tr></table></figure></li>
</ul>
<p>在云端创造联合推理服务,我把其中的镜像替换成国内镜像了，以下是文件内容：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre class="line-numbers language-hljs yaml"><span class="hljs-attr">kind:</span> <span class="hljs-string">JointInferenceService</span><br><span class="hljs-attr">metadata:</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">helmet-detection-inference-example</span><br>  <span class="hljs-attr">namespace:</span> <span class="hljs-string">default</span><br><span class="hljs-attr">spec:</span><br>  <span class="hljs-attr">edgeWorker:</span><br>    <span class="hljs-attr">model:</span><br>      <span class="hljs-attr">name:</span> <span class="hljs-string">&quot;helmet-detection-inference-little-model&quot;</span><br>    <span class="hljs-attr">hardExampleMining:</span><br>      <span class="hljs-attr">name:</span> <span class="hljs-string">&quot;IBT&quot;</span><br>      <span class="hljs-attr">parameters:</span><br>        <span class="hljs-bullet">-</span> <span class="hljs-attr">key:</span> <span class="hljs-string">&quot;threshold_img&quot;</span><br>          <span class="hljs-attr">value:</span> <span class="hljs-string">&quot;0.9&quot;</span><br>        <span class="hljs-bullet">-</span> <span class="hljs-attr">key:</span> <span class="hljs-string">&quot;threshold_box&quot;</span><br>          <span class="hljs-attr">value:</span> <span class="hljs-string">&quot;0.9&quot;</span><br>    <span class="hljs-attr">template:</span><br>      <span class="hljs-attr">spec:</span><br>        <span class="hljs-attr">nodeName:</span> <span class="hljs-string">$EDGE_NODE</span><br>        <span class="hljs-attr">dnsPolicy:</span> <span class="hljs-string">ClusterFirstWithHostNet</span><br>        <span class="hljs-attr">containers:</span><br>        <span class="hljs-bullet">-</span> <span class="hljs-attr">image:</span> <span class="hljs-string">swr.cn-north-4.myhuaweicloud.com/ddn-k8s/docker.io/kubeedge/sedna-example-joint-inference-helmet-detection-little:v0.3.0</span><br>          <span class="hljs-attr">imagePullPolicy:</span> <span class="hljs-string">IfNotPresent</span><br>          <span class="hljs-attr">name:</span>  <span class="hljs-string">little-model</span><br>          <span class="hljs-attr">env:</span>  <span class="hljs-comment"># user defined environments</span><br>          <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">input_shape</span><br>            <span class="hljs-attr">value:</span> <span class="hljs-string">&quot;416,736&quot;</span><br>          <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">&quot;video_url&quot;</span><br>            <span class="hljs-attr">value:</span> <span class="hljs-string">&quot;rtsp://localhost/video&quot;</span><br>          <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">&quot;all_examples_inference_output&quot;</span><br>            <span class="hljs-attr">value:</span> <span class="hljs-string">&quot;/data/output&quot;</span><br>          <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">&quot;hard_example_cloud_inference_output&quot;</span><br>            <span class="hljs-attr">value:</span> <span class="hljs-string">&quot;/data/hard_example_cloud_inference_output&quot;</span><br>          <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">&quot;hard_example_edge_inference_output&quot;</span><br>            <span class="hljs-attr">value:</span> <span class="hljs-string">&quot;/data/hard_example_edge_inference_output&quot;</span><br>          <span class="hljs-attr">resources:</span>  <span class="hljs-comment"># user defined resources</span><br>            <span class="hljs-attr">requests:</span><br>              <span class="hljs-attr">memory:</span> <span class="hljs-string">64M</span><br>              <span class="hljs-attr">cpu:</span> <span class="hljs-string">100m</span><br>            <span class="hljs-attr">limits:</span><br>              <span class="hljs-attr">memory:</span> <span class="hljs-string">2Gi</span><br>          <span class="hljs-attr">volumeMounts:</span><br>            <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">outputdir</span><br>              <span class="hljs-attr">mountPath:</span> <span class="hljs-string">/data/</span><br>        <span class="hljs-attr">volumes:</span>   <span class="hljs-comment"># user defined volumes</span><br>          <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">outputdir</span><br>            <span class="hljs-attr">hostPath:</span><br>              <span class="hljs-comment"># user must create the directory in host</span><br>              <span class="hljs-attr">path:</span> <span class="hljs-string">/joint_inference/output</span><br>              <span class="hljs-attr">type:</span> <span class="hljs-string">Directory</span><br>  <span class="hljs-attr">cloudWorker:</span><br>    <span class="hljs-attr">model:</span><br>      <span class="hljs-attr">name:</span> <span class="hljs-string">&quot;helmet-detection-inference-big-model&quot;</span><br>    <span class="hljs-attr">template:</span><br>      <span class="hljs-attr">spec:</span><br>        <span class="hljs-attr">nodeName:</span> <span class="hljs-string">$CLOUD_NODE</span><br>        <span class="hljs-attr">dnsPolicy:</span> <span class="hljs-string">ClusterFirstWithHostNet</span><br>        <span class="hljs-attr">containers:</span><br>          <span class="hljs-bullet">-</span> <span class="hljs-attr">image:</span> <span class="hljs-string">swr.cn-north-4.myhuaweicloud.com/ddn-k8s/docker.io/kubeedge/sedna-example-joint-inference-helmet-detection-big:v0.3.0</span><br>            <span class="hljs-attr">name:</span>  <span class="hljs-string">big-model</span><br>            <span class="hljs-attr">imagePullPolicy:</span> <span class="hljs-string">IfNotPresent</span><br>            <span class="hljs-attr">env:</span>  <span class="hljs-comment"># user defined environments</span><br>              <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">&quot;input_shape&quot;</span><br>                <span class="hljs-attr">value:</span> <span class="hljs-string">&quot;544,544&quot;</span><br>            <span class="hljs-attr">resources:</span>  <span class="hljs-comment"># user defined resources</span><br>              <span class="hljs-attr">requests:</span><br>                <span class="hljs-attr">memory:</span> <span class="hljs-string">2Gi</span><br><span class="hljs-string"><code class="language-hljs yaml"><span class="hljs-attr">kind:</span> <span class="hljs-string">JointInferenceService</span><br><span class="hljs-attr">metadata:</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">helmet-detection-inference-example</span><br>  <span class="hljs-attr">namespace:</span> <span class="hljs-string">default</span><br><span class="hljs-attr">spec:</span><br>  <span class="hljs-attr">edgeWorker:</span><br>    <span class="hljs-attr">model:</span><br>      <span class="hljs-attr">name:</span> <span class="hljs-string">&quot;helmet-detection-inference-little-model&quot;</span><br>    <span class="hljs-attr">hardExampleMining:</span><br>      <span class="hljs-attr">name:</span> <span class="hljs-string">&quot;IBT&quot;</span><br>      <span class="hljs-attr">parameters:</span><br>        <span class="hljs-bullet">-</span> <span class="hljs-attr">key:</span> <span class="hljs-string">&quot;threshold_img&quot;</span><br>          <span class="hljs-attr">value:</span> <span class="hljs-string">&quot;0.9&quot;</span><br>        <span class="hljs-bullet">-</span> <span class="hljs-attr">key:</span> <span class="hljs-string">&quot;threshold_box&quot;</span><br>          <span class="hljs-attr">value:</span> <span class="hljs-string">&quot;0.9&quot;</span><br>    <span class="hljs-attr">template:</span><br>      <span class="hljs-attr">spec:</span><br>        <span class="hljs-attr">nodeName:</span> <span class="hljs-string">$EDGE_NODE</span><br>        <span class="hljs-attr">dnsPolicy:</span> <span class="hljs-string">ClusterFirstWithHostNet</span><br>        <span class="hljs-attr">containers:</span><br>        <span class="hljs-bullet">-</span> <span class="hljs-attr">image:</span> <span class="hljs-string">swr.cn-north-4.myhuaweicloud.com/ddn-k8s/docker.io/kubeedge/sedna-example-joint-inference-helmet-detection-little:v0.3.0</span><br>          <span class="hljs-attr">imagePullPolicy:</span> <span class="hljs-string">IfNotPresent</span><br>          <span class="hljs-attr">name:</span>  <span class="hljs-string">little-model</span><br>          <span class="hljs-attr">env:</span>  <span class="hljs-comment"># user defined environments</span><br>          <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">input_shape</span><br>            <span class="hljs-attr">value:</span> <span class="hljs-string">&quot;416,736&quot;</span><br>          <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">&quot;video_url&quot;</span><br>            <span class="hljs-attr">value:</span> <span class="hljs-string">&quot;rtsp://localhost/video&quot;</span><br>          <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">&quot;all_examples_inference_output&quot;</span><br>            <span class="hljs-attr">value:</span> <span class="hljs-string">&quot;/data/output&quot;</span><br>          <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">&quot;hard_example_cloud_inference_output&quot;</span><br>            <span class="hljs-attr">value:</span> <span class="hljs-string">&quot;/data/hard_example_cloud_inference_output&quot;</span><br>          <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">&quot;hard_example_edge_inference_output&quot;</span><br>            <span class="hljs-attr">value:</span> <span class="hljs-string">&quot;/data/hard_example_edge_inference_output&quot;</span><br>          <span class="hljs-attr">resources:</span>  <span class="hljs-comment"># user defined resources</span><br>            <span class="hljs-attr">requests:</span><br>              <span class="hljs-attr">memory:</span> <span class="hljs-string">64M</span><br>              <span class="hljs-attr">cpu:</span> <span class="hljs-string">100m</span><br>            <span class="hljs-attr">limits:</span><br>              <span class="hljs-attr">memory:</span> <span class="hljs-string">2Gi</span><br>          <span class="hljs-attr">volumeMounts:</span><br>            <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">outputdir</span><br>              <span class="hljs-attr">mountPath:</span> <span class="hljs-string">/data/</span><br>        <span class="hljs-attr">volumes:</span>   <span class="hljs-comment"># user defined volumes</span><br>          <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">outputdir</span><br>            <span class="hljs-attr">hostPath:</span><br>              <span class="hljs-comment"># user must create the directory in host</span><br>              <span class="hljs-attr">path:</span> <span class="hljs-string">/joint_inference/output</span><br>              <span class="hljs-attr">type:</span> <span class="hljs-string">Directory</span><br>  <span class="hljs-attr">cloudWorker:</span><br>    <span class="hljs-attr">model:</span><br>      <span class="hljs-attr">name:</span> <span class="hljs-string">&quot;helmet-detection-inference-big-model&quot;</span><br>    <span class="hljs-attr">template:</span><br>      <span class="hljs-attr">spec:</span><br>        <span class="hljs-attr">nodeName:</span> <span class="hljs-string">$CLOUD_NODE</span><br>        <span class="hljs-attr">dnsPolicy:</span> <span class="hljs-string">ClusterFirstWithHostNet</span><br>        <span class="hljs-attr">containers:</span><br>          <span class="hljs-bullet">-</span> <span class="hljs-attr">image:</span> <span class="hljs-string">swr.cn-north-4.myhuaweicloud.com/ddn-k8s/docker.io/kubeedge/sedna-example-joint-inference-helmet-detection-big:v0.3.0</span><br>            <span class="hljs-attr">name:</span>  <span class="hljs-string">big-model</span><br>            <span class="hljs-attr">imagePullPolicy:</span> <span class="hljs-string">IfNotPresent</span><br>            <span class="hljs-attr">env:</span>  <span class="hljs-comment"># user defined environments</span><br>              <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">&quot;input_shape&quot;</span><br>                <span class="hljs-attr">value:</span> <span class="hljs-string">&quot;544,544&quot;</span><br>            <span class="hljs-attr">resources:</span>  <span class="hljs-comment"># user defined resources</span><br>              <span class="hljs-attr">requests:</span><br>                <span class="hljs-attr">memory:</span> <span class="hljs-string">2Gi</span><br><span class="hljs-string">EOF</span><br><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></td></tr></table></figure>
<h1 id="边缘端模拟视频流进行推理"><a href="#边缘端模拟视频流进行推理" class="headerlink" title="边缘端模拟视频流进行推理"></a>边缘端模拟视频流进行推理</h1><ul>
<li>1.安装开源视频流服务器 EasyDarwin。</li>
<li>2.启动 EasyDarwin 服务器。</li>
<li>3.下载视频。</li>
<li>4.向推理服务可连接的网址（如 <code>rtsp://localhost/video</code> ）推送视频流。<br>（EasyDarwin-linux-8.1.0-1901141151.tar.gz在文档上给的地址应该是找不到了，但是我在一个网站上找到并且下载下来了）<figure class="highlight bash"><table><tr><td class="code"><pre class="line-numbers language-hljs bash"><span class="hljs-built_in">cd</span> EasyDarwin-linux-8.1.0-1901141151<br>./start.sh<br><br><span class="hljs-built_in">mkdir</span> -p /data/video<br><span class="hljs-built_in"><code class="language-hljs bash"><span class="hljs-built_in">cd</span> EasyDarwin-linux-8.1.0-1901141151<br>./start.sh<br><br><span class="hljs-built_in">mkdir</span> -p /data/video<br><span class="hljs-built_in">cd</span> /data/video<br>wget https://kubeedge.obs.cn-north-1.myhuaweicloud.com/examples/helmet-detection-inference/video.tar.gz<br>tar -zxvf video.tar.gz<br><br>ffmpeg -re -i /data/video/video.mp4 -vcodec libx264 -f rtsp rtsp://localhost/video<br><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></td></tr></table></figure></li>
</ul>
<p>正常运行的话，pod都是<code>running</code>状态，而且可以在 JointInferenceService 配置中定义的输出路径（如 <code>/joint_inference/output</code> ）中查看推理结果。</p>
</p></div><div class="share"><span>Share</span>&nbsp;<span class="soc"><a class="fa fa-bookmark" href="javascript:(function(){EN_CLIP_HOST='http://www.evernote.com';try{var%20x=document.createElement('SCRIPT');x.type='text/javascript';x.src=EN_CLIP_HOST+'/public/bookmarkClipper.js?'+(new%20Date().getTime()/100000);document.getElementsByTagName('head')[0].appendChild(x);}catch(e){location.href=EN_CLIP_HOST+'/clip.action?url='+encodeURIComponent(location.href)+'&amp;title='+encodeURIComponent(document.title);}})();" ref="nofollow" target="_blank"></a></span><span class="soc"><a class="fa fa-weibo" href="javascript:void((function(s,d,e){try{}catch(e){}var f='http://service.weibo.com/share/share.php?',u=d.location.href,p=['url=',e(u),'&amp;title=',e(d.title),'&amp;appkey=2924220432'].join('');function a(){if(!window.open([f,p].join(''),'mb',['toolbar=0,status=0,resizable=1,width=620,height=450,left=',(s.width-620)/2,',top=',(s.height-450)/2].join('')))u.href=[f,p].join('');};if(/Firefox/.test(navigator.userAgent)){setTimeout(a,0)}else{a()}})(screen,document,encodeURIComponent));"></a></span><span class="soc"><a class="fa fa-twitter" target="_blank" rel="noopener" href="http://twitter.com/home?status=https://shemol.tech/2024/06/10/KubeEdge-Sedna运行联合推理实例/%20Shemol's Blog%20KubeEdge-Sedna运行联合推理实例"></a></span></div><div class="pagination"><p class="clearfix"><span>&nbsp;</span><span class="next pagbuttons"><a role="navigation" href="/2024/06/10/%E9%83%A8%E7%BD%B2KubeEdge%E3%80%81Edgemesh%E3%80%81Sedna/" title="部署KubeEdge、Edgemesh、Sedna">Next post: 部署KubeEdge、Edgemesh、Sedna&nbsp;<i class="fa fa-angle-double-right"></i></a></span></p></div></div></div></div><div class="visible-xs site-bottom-footer"><footer><p>&copy;&nbsp;2024&nbsp;<a target="_blank" href="https://shemol.tech" rel="noopener noreferrer">Shemol</a></p><p>Theme&nbsp;<a target="_blank" href="https://github.com/SumiMakito/hexo-theme-typography" rel="noopener noreferrer">Typography</a>&nbsp;by&nbsp;<a target="_blank" href="https://www.keep.moe" rel="noopener noreferrer">Makito</a></p><p>Proudly published with&nbsp;<a target="_blank" href="https://hexo.io" rel="noopener noreferrer">Hexo</a></p></footer></div></div></div></div><script src="/js/jquery-3.1.0.min.js"></script><script src="/js/bootstrap.min.js"></script><script src="/js/jquery-migrate-1.2.1.min.js"></script><script src="/js/jquery.appear.js"></script><script src="/js/google-analytics.js"></script><script src="/js/typography.js"></script></body></html>